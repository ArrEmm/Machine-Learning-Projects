{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNGcAWSkmphp2g0Fv7gBPto",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArrEmm/Machine-Learning-Projects/blob/main/Spam_email_filter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPF3CjG5dxRH",
        "outputId": "47b11553-d447-4e9f-82bc-0085db9c7f1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pandas scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
        "column_names = [\"word_freq_make\", \"word_freq_address\", \"word_freq_all\", \"word_freq_3d\", \"word_freq_our\",\n",
        "                \"word_freq_over\", \"word_freq_remove\", \"word_freq_internet\", \"word_freq_order\", \"word_freq_mail\",\n",
        "                \"word_freq_receive\", \"word_freq_will\", \"word_freq_people\", \"word_freq_report\", \"word_freq_addresses\",\n",
        "                \"word_freq_free\", \"word_freq_business\", \"word_freq_email\", \"word_freq_you\", \"word_freq_credit\",\n",
        "                \"word_freq_your\", \"word_freq_font\", \"word_freq_000\", \"word_freq_money\", \"word_freq_hp\", \"word_freq_hpl\",\n",
        "                \"word_freq_george\", \"word_freq_650\", \"word_freq_lab\", \"word_freq_labs\", \"word_freq_telnet\",\n",
        "                \"word_freq_857\", \"word_freq_data\", \"word_freq_415\", \"word_freq_85\", \"word_freq_technology\",\n",
        "                \"word_freq_1999\", \"word_freq_parts\", \"word_freq_pm\", \"word_freq_direct\", \"word_freq_cs\", \"word_freq_meeting\",\n",
        "                \"word_freq_original\", \"word_freq_project\", \"word_freq_re\", \"word_freq_edu\", \"word_freq_table\", \"word_freq_conference\",\n",
        "                \"char_freq_semicolon\", \"char_freq_leftparen\", \"char_freq_leftsquare\", \"char_freq_exclamation\", \"char_freq_dollar\",\n",
        "                \"char_freq_hash\", \"capital_run_length_average\", \"capital_run_length_longest\", \"capital_run_length_total\", \"spam\"]\n",
        "\n",
        "# Load the data into a Pandas DataFrame\n",
        "data = pd.read_csv(url, names=column_names)\n"
      ],
      "metadata": {
        "id": "uqrjk33Hd-OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the data\n",
        "print(data.head())\n",
        "\n",
        "# Features (X) and target variable (y)\n",
        "X = data.drop(\"spam\", axis=1)\n",
        "y = data[\"spam\"]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_a_FYS7ezhi",
        "outputId": "9ac3cb72-cf0d-4e02-a49c-d456c7eb7d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   word_freq_make  word_freq_address  word_freq_all  word_freq_3d  \\\n",
            "0            0.00               0.64           0.64           0.0   \n",
            "1            0.21               0.28           0.50           0.0   \n",
            "2            0.06               0.00           0.71           0.0   \n",
            "3            0.00               0.00           0.00           0.0   \n",
            "4            0.00               0.00           0.00           0.0   \n",
            "\n",
            "   word_freq_our  word_freq_over  word_freq_remove  word_freq_internet  \\\n",
            "0           0.32            0.00              0.00                0.00   \n",
            "1           0.14            0.28              0.21                0.07   \n",
            "2           1.23            0.19              0.19                0.12   \n",
            "3           0.63            0.00              0.31                0.63   \n",
            "4           0.63            0.00              0.31                0.63   \n",
            "\n",
            "   word_freq_order  word_freq_mail  ...  char_freq_semicolon  \\\n",
            "0             0.00            0.00  ...                 0.00   \n",
            "1             0.00            0.94  ...                 0.00   \n",
            "2             0.64            0.25  ...                 0.01   \n",
            "3             0.31            0.63  ...                 0.00   \n",
            "4             0.31            0.63  ...                 0.00   \n",
            "\n",
            "   char_freq_leftparen  char_freq_leftsquare  char_freq_exclamation  \\\n",
            "0                0.000                   0.0                  0.778   \n",
            "1                0.132                   0.0                  0.372   \n",
            "2                0.143                   0.0                  0.276   \n",
            "3                0.137                   0.0                  0.137   \n",
            "4                0.135                   0.0                  0.135   \n",
            "\n",
            "   char_freq_dollar  char_freq_hash  capital_run_length_average  \\\n",
            "0             0.000           0.000                       3.756   \n",
            "1             0.180           0.048                       5.114   \n",
            "2             0.184           0.010                       9.821   \n",
            "3             0.000           0.000                       3.537   \n",
            "4             0.000           0.000                       3.537   \n",
            "\n",
            "   capital_run_length_longest  capital_run_length_total  spam  \n",
            "0                          61                       278     1  \n",
            "1                         101                      1028     1  \n",
            "2                         485                      2259     1  \n",
            "3                          40                       191     1  \n",
            "4                          40                       191     1  \n",
            "\n",
            "[5 rows x 58 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "n-ZnNPB0fwIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Create and train the Naive Bayes classifier\n",
        "naive_bayes_classifier = MultinomialNB()\n",
        "naive_bayes_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = naive_bayes_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n",
        "print(f\"Classification Report:\\n{classification_rep}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJxRRr7hechH",
        "outputId": "14f72fd6-6082-4c9f-db38-6d7330e54b24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7861020629750272\n",
            "Confusion Matrix:\n",
            "[[445  86]\n",
            " [111 279]]\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.84      0.82       531\n",
            "           1       0.76      0.72      0.74       390\n",
            "\n",
            "    accuracy                           0.79       921\n",
            "   macro avg       0.78      0.78      0.78       921\n",
            "weighted avg       0.79      0.79      0.79       921\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define the parameter grid for tuning\n",
        "param_grid = {\n",
        "    'learning_rate': [0.1, 0.01, 0.001],\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [3, 5, 7],\n",
        "}\n",
        "\n",
        "# Create the XGBoost classifier\n",
        "xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', random_state=42)\n",
        "\n",
        "# Perform grid search with cross-validation\n",
        "grid_search = GridSearchCV(estimator=xgb_classifier, param_grid=param_grid, cv=3, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get the best parameters\n",
        "best_params = grid_search.best_params_\n",
        "\n",
        "# Train the model with the best parameters\n",
        "best_xgb_classifier = xgb.XGBClassifier(objective='binary:logistic', random_state=42, **best_params)\n",
        "best_xgb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the tuned model\n",
        "y_pred_tuned = best_xgb_classifier.predict(X_test)\n",
        "accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
        "\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Tuned Model Accuracy: {accuracy_tuned}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktoEmTMJi614",
        "outputId": "0ab1c1ed-37e4-4146-aebd-10aa7e9df245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
            "Tuned Model Accuracy: 0.9587404994571118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bclaTtzsoG8y",
        "outputId": "62241930-f168-4ec0-d350-5318d4950f8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#feature_names = vectorizer.get_feature_names_out()\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Create a CountVectorizer with binary=True to represent word presence as 1 or 0\n",
        "#vectorizer = CountVectorizer(binary=True)\n",
        "\n",
        "# Fit and transform the email content\n",
        "#email_features = vectorizer.fit_transform([sample_email])\n",
        "\n",
        "# Convert the feature matrix to a DataFrame for better visualization\n",
        "def calculate_email_features(email_content):\n",
        "  tokens = nltk.word_tokenize(email_content)\n",
        "  normalized_tokens = [token.lower() for token in tokens]\n",
        "  word_freq_make = tokens.count('make')\n",
        "  word_freq_address= tokens.count('address')\n",
        "  word_freq_all= tokens.count('all')\n",
        "  word_freq_3d= tokens.count('3d')\n",
        "  word_freq_our= tokens.count('our')\n",
        "  word_freq_over= tokens.count('over')\n",
        "  word_freq_remove= tokens.count('remove')\n",
        "  word_freq_internet= tokens.count('internet')\n",
        "  word_freq_order= tokens.count('order')\n",
        "  word_freq_mail= tokens.count('mail')\n",
        "  word_freq_receive= tokens.count('receiver')\n",
        "  word_freq_will= tokens.count('will')\n",
        "  word_freq_people= tokens.count('people')\n",
        "  word_freq_report= tokens.count('report')\n",
        "  word_freq_addresses= tokens.count('addresses')\n",
        "  word_freq_free= tokens.count('free')\n",
        "  word_freq_business= tokens.count('business')\n",
        "  word_freq_email= tokens.count('email')\n",
        "  word_freq_you= tokens.count('you')\n",
        "  word_freq_credit= tokens.count('credit')\n",
        "  word_freq_your= tokens.count('your')\n",
        "  word_freq_font= tokens.count('font')\n",
        "  word_freq_000= tokens.count('000')\n",
        "  word_freq_money= tokens.count('money')\n",
        "  word_freq_hp= tokens.count('hp')\n",
        "  word_freq_hpl= tokens.count('hpl')\n",
        "  word_freq_george= tokens.count('george')\n",
        "  word_freq_650= tokens.count('650')\n",
        "  word_freq_lab= tokens.count('lab')\n",
        "  word_freq_labs= tokens.count('labs')\n",
        "  word_freq_telnet= tokens.count('telnet')\n",
        "  word_freq_857= tokens.count('857')\n",
        "  word_freq_data= tokens.count('data')\n",
        "  word_freq_415= tokens.count('415')\n",
        "  word_freq_85= tokens.count('85')\n",
        "  word_freq_technology= tokens.count('technology')\n",
        "  word_freq_1999= tokens.count('1999')\n",
        "  word_freq_parts= tokens.count('parts')\n",
        "  word_freq_pm= tokens.count('pm')\n",
        "  word_freq_direct= tokens.count('direct')\n",
        "  word_freq_cs= tokens.count('cs')\n",
        "  word_freq_meeting= tokens.count('meetings')\n",
        "  word_freq_original= tokens.count('original')\n",
        "  word_freq_project= tokens.count('project')\n",
        "  word_freq_re= tokens.count('re')\n",
        "  word_freq_edu= tokens.count('edu')\n",
        "  word_freq_table= tokens.count('table')\n",
        "  word_freq_conference= tokens.count('conference')\n",
        "  char_freq_semicolon= tokens.count(';')\n",
        "  char_freq_leftparen= tokens.count('(')\n",
        "  char_freq_leftsquare= tokens.count('[')\n",
        "  char_freq_exclamation= tokens.count('!')\n",
        "  char_freq_dollar= tokens.count('$')\n",
        "  char_freq_hash= tokens.count('#')\n",
        "\n",
        "\n",
        "  # Find all capital letter runs using regular expression\n",
        "  capital_runs = re.findall(r'[A-Z]+', email_content)\n",
        "\n",
        "  if not capital_runs:\n",
        "      return 0, 0, 0  # No capital runs found\n",
        "\n",
        "  # Calculate capital run length average\n",
        "  capital_run_length_average = sum(len(run) for run in capital_runs) / len(capital_runs)\n",
        "\n",
        "  # Calculate longest capital run\n",
        "  longest_run = max(capital_runs, key=len)\n",
        "  capital_run_length_longest=len(longest_run)\n",
        "  # Calculate total capital run length\n",
        "  capital_run_length_total = sum(len(run) for run in capital_runs)\n",
        "\n",
        "\n",
        "  return [word_freq_make,word_freq_address,word_freq_all,word_freq_3d,word_freq_our, word_freq_over,word_freq_remove,word_freq_internet,word_freq_order,word_freq_mail,word_freq_receive,word_freq_will,word_freq_people,word_freq_report,word_freq_addresses,word_freq_free,word_freq_business,word_freq_email,word_freq_you,word_freq_credit,word_freq_your,word_freq_font,word_freq_000,word_freq_money,word_freq_hp,word_freq_hpl,word_freq_george,word_freq_650,word_freq_lab,word_freq_labs,word_freq_telnet,word_freq_857,word_freq_data,word_freq_415,word_freq_85,word_freq_technology,word_freq_1999,word_freq_parts,word_freq_pm,word_freq_direct,word_freq_cs,word_freq_meeting,word_freq_original,word_freq_project,word_freq_re,word_freq_edu,word_freq_table,word_freq_conference,char_freq_semicolon,char_freq_leftparen,char_freq_leftsquare,char_freq_exclamation,char_freq_dollar,char_freq_hash,capital_run_length_average,capital_run_length_longest, capital_run_length_total]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQfAcl7fejhM",
        "outputId": "cc1dde74-aeb5-45bc-c32d-0cf58a9413a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1.0, 1, 3]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example email content\n",
        "sample_email = \"\"\"\n",
        "Congratulations! You've won a special prize. Click the link below to claim your reward:\n",
        "https://example.com/claim_prize\n",
        "\"\"\"\n",
        "email_features = calculate_email_features(sample_email)\n",
        "prediction = naive_bayes_classifier.predict([email_features])\n",
        "print(f\"Prediction for the new email: {'Spam' if prediction[0] == 1 else 'Not Spam'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNg-Dn1wSyWQ",
        "outputId": "3536577a-54d0-4fa1-8fae-267d817a7e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for the new email: Spam\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but MultinomialNB was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_email = \"\"\"\n",
        "From MAUREEN UDAENU <mauda_2@yahoo.co.uk>:\n",
        "Good Day Dear,\n",
        "Am sorry for the inconveniency it may curse you for using this opportunity to communicating with you for the first time. Well I shall be extremely happy if you will kindly understand the content of my proposal thereby contributing your own quarter.\n",
        "Its true that the message will have some characters, but I want you to choose the best character that should favour us better, so that we should forge ahead in this transaction.\n",
        "Well I am Miss. Maureen Udaenu, and an indigene of G/Bissau, though I left my country as a matter of death scallating because of wars but that was not my primary aim of leaving my country to Dakar Senegal where I am currently staying now, my major reason is because I was humiliated by my late father's relatives as a result of their much focus on material things. I left my country because I was the only child left in my late father's linage and It will not come to an end rather I will ensure I keep the family name on constant remembrance and existing.\n",
        "But the principal aim for my being here is to concentrate well on what I will do in future with the money my late father left in one of the banks in Europe, the money is Five million eight US dollars ($5.8 M). This money was meant for his multi investment projects before death struck him down. This is the principal reason why I am here in this country so that I shall concentrate and be mindful to this everlasting opportunity I inherited and to search for one who will stand on my behalf in the claim.\n",
        "My contacting you is based on your complete capability to move to the Europe bank as soon as you could so that you will have a Table discussion with the bank thereby reclaiming and retransferring this money to your own bank account where it will be confidently be secured for my future investment There are other things that we should discuss as soon as you write back because we need to round up every bit of this matter before all the bank details should be exchanged to enable us come to close end of the whole matter which will lift me up from here to your country with your help and where we should stay for our investment projects as we agreed in the next page. Don't forget that there are some hidden percentage that I have wholeheartedly mapped for you which will be revealed when we come to agreement that you will help me to secure this money in your own easy accessible bank account.\n",
        "Hope to hear from you and it will sound better and encouraging if you will reply with your\n",
        "complete data's so that I shall commence all applications on the need able documents that\n",
        "will ease the direct recommendation and also empowering you as my foreign live partner or\n",
        "my late father's business associate before his death.\n",
        "Regards:\n",
        "Miss. Maureen Udaenu.\n",
        "\"\"\"\n",
        "email_features = calculate_email_features(sample_email)\n",
        "prediction = naive_bayes_classifier.predict([email_features])\n",
        "print(f\"Prediction for the new email: {'Spam' if prediction[0] == 1 else 'Not Spam'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cr4PtRdNPXG",
        "outputId": "b3f6bfde-2c51-4bec-ad98-3a6284bc25ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction for the new email: Spam\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "--By-_qkkf2F"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}