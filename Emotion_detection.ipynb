{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOJlulZyI8BtyuQPPkfr0sB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ArrEmm/Machine-Learning-Projects/blob/main/Emotion_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVnyO5U8uYHo",
        "outputId": "e4d9ad5c-11fd-4e83-e08f-6cf47b415c90"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TdJhDgGG_sv0"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def convert_images_to_bw(input_path, output_path):\n",
        "    # Create output directory if it doesn't exist\n",
        "    if not os.path.exists(output_path):\n",
        "        os.makedirs(output_path)\n",
        "    for emotion in os.listdir(input_path):\n",
        "        emotion_input_path=os.path.join(input_path,emotion)\n",
        "        emotion_output_path=os.path.join(output_path,emotion)\n",
        "        if not os.path.exists(emotion_output_path):\n",
        "            os.makedirs(emotion_output_path)\n",
        "        # Loop through each image in the input dataset\n",
        "        for filename in os.listdir(emotion_input_path):\n",
        "            image_path = os.path.join(emotion_input_path, filename)\n",
        "\n",
        "            # Open the image\n",
        "            with Image.open(image_path) as img:\n",
        "                # Convert the image to black and white\n",
        "                bw_img = img.convert('L')\n",
        "\n",
        "                # Save the black and white image to the output folder\n",
        "                output_emotion_image_path = os.path.join(output_path, emotion)\n",
        "                output_image_path = os.path.join(output_emotion_image_path, filename)\n",
        "                bw_img.save(output_image_path)\n",
        "\n",
        "# Specify the paths to your input (color) and output (black and white) datasets\n",
        "input_train_dataset_path = '/content/drive/MyDrive/Dataset/train'\n",
        "output_train_dataset_path = '/content/drive/MyDrive/BAndWDataset/train'\n",
        "input_test_dataset_path = '/content/drive/MyDrive/Dataset/test'\n",
        "output_test_dataset_path = '/content/drive/MyDrive/BAndWDataset/test'\n",
        "\n",
        "# Call the function to convert images and save them\n",
        "convert_images_to_bw(input_train_dataset_path, output_train_dataset_path)\n",
        "convert_images_to_bw(input_test_dataset_path, output_test_dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB0J33nQ3QDy",
        "outputId": "2858c413-a61a-49e8-f08c-79a84c87adf4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Define the CNN model\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(7, activation='softmax'))  # Assuming 7 emotion classes\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Load and preprocess the dataset using ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/BAndWDataset/train',\n",
        "    target_size=(48, 48),\n",
        "    batch_size=32,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_generator, epochs=10)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('emotion_detection_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QtqgyYcguVeg",
        "outputId": "10119078-d332-4cc4-a88e-df36e022e681"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 28709 images belonging to 7 classes.\n",
            "Epoch 1/10\n",
            "898/898 [==============================] - 145s 156ms/step - loss: 1.6773 - accuracy: 0.3290\n",
            "Epoch 2/10\n",
            "898/898 [==============================] - 100s 112ms/step - loss: 1.4453 - accuracy: 0.4421\n",
            "Epoch 3/10\n",
            "898/898 [==============================] - 99s 111ms/step - loss: 1.3377 - accuracy: 0.4895\n",
            "Epoch 4/10\n",
            "898/898 [==============================] - 100s 111ms/step - loss: 1.2713 - accuracy: 0.5172\n",
            "Epoch 5/10\n",
            "898/898 [==============================] - 101s 113ms/step - loss: 1.2351 - accuracy: 0.5292\n",
            "Epoch 6/10\n",
            "898/898 [==============================] - 102s 113ms/step - loss: 1.1961 - accuracy: 0.5477\n",
            "Epoch 7/10\n",
            "898/898 [==============================] - 102s 113ms/step - loss: 1.1704 - accuracy: 0.5561\n",
            "Epoch 8/10\n",
            "898/898 [==============================] - 101s 112ms/step - loss: 1.1440 - accuracy: 0.5682\n",
            "Epoch 9/10\n",
            "898/898 [==============================] - 102s 113ms/step - loss: 1.1210 - accuracy: 0.5762\n",
            "Epoch 10/10\n",
            "898/898 [==============================] - 100s 111ms/step - loss: 1.1027 - accuracy: 0.5839\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "model = models.load_model('emotion_detection_model.h5')\n",
        "\n",
        "# Load and preprocess the test dataset using ImageDataGenerator\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/BAndWDataset/test',\n",
        "    target_size=(48, 48),\n",
        "    batch_size=32,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='categorical',\n",
        "    shuffle=False  # Ensure that the order of predictions matches the order of true labels\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "eval_results = model.evaluate(test_generator)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(test_generator)\n",
        "\n",
        "# Convert predictions and true labels to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "true_labels = test_generator.classes\n",
        "\n",
        "# Print evaluation results\n",
        "print(\"Test Accuracy: {:.2f}%\".format(eval_results[1] * 100))\n",
        "\n",
        "# Calculate and print classification report\n",
        "class_report = classification_report(true_labels, predicted_labels, target_names=test_generator.class_indices)\n",
        "print(\"Classification Report:\\n\", class_report)\n",
        "\n",
        "# Calculate and print confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuFR9YoY3Z_m",
        "outputId": "d7389ac2-f32c-4d40-af70-1979d0bd19f8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7178 images belonging to 7 classes.\n",
            "225/225 [==============================] - 20s 89ms/step - loss: 1.1528 - accuracy: 0.5670\n",
            "225/225 [==============================] - 20s 88ms/step\n",
            "Test Accuracy: 56.70%\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "       angry       0.42      0.61      0.49       958\n",
            "   disgusted       0.78      0.06      0.12       111\n",
            "     fearful       0.38      0.33      0.35      1024\n",
            "       happy       0.83      0.77      0.80      1774\n",
            "     neutral       0.53      0.54      0.54      1233\n",
            "         sad       0.46      0.41      0.44      1247\n",
            "   surprised       0.69      0.70      0.70       831\n",
            "\n",
            "    accuracy                           0.57      7178\n",
            "   macro avg       0.58      0.49      0.49      7178\n",
            "weighted avg       0.58      0.57      0.57      7178\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 583    0  103   33  108  110   21]\n",
            " [  71    7   11    2    8   10    2]\n",
            " [ 212    0  341   49  109  194  119]\n",
            " [ 114    0   66 1370  103   74   47]\n",
            " [ 145    1  107   82  669  188   41]\n",
            " [ 220    0  172   74  235  517   29]\n",
            " [  57    1  100   36   35   19  583]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "metadata": {
        "id": "wBrC4MrK9eCy"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "35jY6I6n-lUj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img1= cv2.imread('/content/im7.png')\n",
        "print(img1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0Y0lQtw-U25",
        "outputId": "f390773c-47a8-49b4-f433-dabf7ba0d200"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[234 234 234]\n",
            "  [233 233 233]\n",
            "  [228 228 228]\n",
            "  ...\n",
            "  [225 225 225]\n",
            "  [229 229 229]\n",
            "  [224 224 224]]\n",
            "\n",
            " [[229 229 229]\n",
            "  [230 230 230]\n",
            "  [232 232 232]\n",
            "  ...\n",
            "  [224 224 224]\n",
            "  [221 221 221]\n",
            "  [218 218 218]]\n",
            "\n",
            " [[232 232 232]\n",
            "  [228 228 228]\n",
            "  [235 235 235]\n",
            "  ...\n",
            "  [226 226 226]\n",
            "  [226 226 226]\n",
            "  [226 226 226]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[215 215 215]\n",
            "  [181 181 181]\n",
            "  [149 149 149]\n",
            "  ...\n",
            "  [108 108 108]\n",
            "  [159 159 159]\n",
            "  [169 169 169]]\n",
            "\n",
            " [[166 166 166]\n",
            "  [140 140 140]\n",
            "  [123 123 123]\n",
            "  ...\n",
            "  [104 104 104]\n",
            "  [164 164 164]\n",
            "  [169 169 169]]\n",
            "\n",
            " [[142 142 142]\n",
            "  [123 123 123]\n",
            "  [118 118 118]\n",
            "  ...\n",
            "  [ 95  95  95]\n",
            "  [164 164 164]\n",
            "  [169 169 169]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(img1[:,:,::-1])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "6ACYvDge-p-Z",
        "outputId": "8d8f5302-c2a8-4249-ead3-54e53b25e43f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "model = models.load_model('emotion_detection_model.h5')\n",
        "\n",
        "img_path = '/content/im7.png'  # Replace with the path to your preprocessed grayscale image\n",
        "img = image.load_img(img_path, target_size=(48, 48), color_mode='grayscale')\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array /= 255.0  # Normalize the pixel values\n",
        "\n",
        "# Make predictions on the single image\n",
        "predictions = model.predict(img_array)\n",
        "\n",
        "# Convert predictions to class label\n",
        "predicted_label = np.argmax(predictions[0])\n",
        "\n",
        "# Get the emotion class based on the predicted label\n",
        "emotion_classes = {0: 'Angry', 1: 'Disgust', 2: 'Fear', 3: 'Happy', 4: 'Sad', 5: 'Surprise', 6: 'Neutral'}\n",
        "predicted_emotion = emotion_classes[predicted_label]\n",
        "\n",
        "# Print the predicted emotion\n",
        "print(\"Predicted Emotion: {}\".format(predicted_emotion))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZBjJveV-tF7",
        "outputId": "f608a64e-7567-4b1c-c036-4e265711a335"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 547ms/step\n",
            "Predicted Emotion: Happy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G38XDqe3_jxl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}